{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anoukB/tutorial_from_tracking_to_posture_dynamics/blob/main/Part_3_Transition_Matrix_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fcb6e8a",
      "metadata": {
        "id": "4fcb6e8a"
      },
      "source": [
        "# Interpreting the dynamics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Installations\n",
        "This first section makes sure you have all the necessary functions to run this tutorial smoothly."
      ],
      "metadata": {
        "id": "dTqmzANGE-Xs"
      },
      "id": "dTqmzANGE-Xs"
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary environment for display of videos\n",
        "!pip install -U kora\n",
        "from kora.drive import upload_public\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "Goa_KKmLFJcu"
      },
      "id": "Goa_KKmLFJcu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary environments specific to this notebook\n",
        "\n",
        "!pip install umap-learn\n",
        "!pip install umap-learn[plot]\n",
        "!pip install msmtools"
      ],
      "metadata": {
        "id": "9P1RnHLGFLzm"
      },
      "id": "9P1RnHLGFLzm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clone the repository with all files, images and videos. This will result in a folder called cloned-repo\n",
        "!git clone -l -s https://github.com/anoukB/tutorial_from_tracking_to_posture_dynamics cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls  #Listo of all elements in the repo"
      ],
      "metadata": {
        "id": "oNmUVlbp1Nm5"
      },
      "id": "oNmUVlbp1Nm5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "8Ff8Bonn1RpZ"
      },
      "id": "8Ff8Bonn1RpZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***STOP HERE :)***\n",
        "\n",
        "You need to set the directory for all the files that will be used in the tutorial. The folders from GitHub have been imported in your version of the tutorial, so you need to make sure this is correct. The most likely directory would be the one in the example, but in case anything is different in your case, we will let you set it up."
      ],
      "metadata": {
        "id": "hU3KCFNW1Tcz"
      },
      "id": "hU3KCFNW1Tcz"
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "#directory = '/content/cloned-repo/'\n",
        "\n",
        "directory ='/content/cloned-repo/'"
      ],
      "metadata": {
        "id": "5AHADZ831XB7"
      },
      "id": "5AHADZ831XB7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa439ca",
      "metadata": {
        "id": "6fa439ca"
      },
      "outputs": [],
      "source": [
        "#Imports for this tutorial\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.colors as colors\n",
        "import os\n",
        "import scipy\n",
        "import math\n",
        "import umap.plot\n",
        "import matplotlib.animation as anim\n",
        "from sklearn import preprocessing\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "#Load functions from other files\n",
        "import sys\n",
        "path_to_module = directory\n",
        "sys.path.append(path_to_module)\n",
        "import clustering_methods as cl\n",
        "import operator_calculations as op_calc\n",
        "import delay_embedding_1D as embed\n",
        "import matplotlib.animation as anim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a function to display pictures easily\n",
        "def display_picture(url):\n",
        "  im = plt.imread(url)\n",
        "\n",
        "  fig, axs = plt.subplots(ncols=1, nrows=1)\n",
        "  axs.imshow(im, cmap='gray')\n",
        "  axs.set_axis_off()"
      ],
      "metadata": {
        "id": "QU-nEvlnFbB4"
      },
      "id": "QU-nEvlnFbB4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e193b1",
      "metadata": {
        "id": "b6e193b1"
      },
      "outputs": [],
      "source": [
        "# Load the file with the Principal Components TS made in previous tutorial\n",
        "dir_file_storage = directory  # Choose the directory where you put the file\n",
        "filename = 'file_principal_components_time_series_larva.csv'  #Write down your filename\n",
        "PC_ts = np.loadtxt(dir_file_storage + filename  , delimiter = \",\")\n",
        "\n",
        "#Make the trajectory matrix with proper parameters found in Part 2\n",
        "K_opt = 25\n",
        "M_opt = 5\n",
        "traj_matrix = embed.trajectory_matrix(PC_ts,K=K_opt-1)\n",
        "\n",
        "# Extract the singular modes\n",
        "u,s,v = np.linalg.svd(traj_matrix,full_matrices=False)\n",
        "u_withVar = np.dot(u, np.diag(s))[:,:M_opt] #Ponderate U with variance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "pcK_rONCFqZL"
      },
      "id": "pcK_rONCFqZL"
    },
    {
      "cell_type": "markdown",
      "id": "58b91747",
      "metadata": {
        "id": "58b91747"
      },
      "source": [
        "In the last part of this tutorial series, we aim to interpret the state space built in Part 2 by suggesting a model for its dynamics.\n",
        "\n",
        " We will make an important assumption: our system behaves as a Markov model. A dynamical system is Markov if it is memory-less. In other words, if we only need the information in the current step to predict the next. It is a strong assumption, but we will verify its validity in the tutorial. The first reason we are allowed to make this assumption is because we found an embedding of the state space that maximizes predictability. By doing so, we recovered enough information to be able to model the system as Markovian, which is why we will work with the underlying hypothesis that with enough states, we accurately model the system as Markov.\n",
        "\n",
        "\n",
        "Why do we care about Markovianity?\n",
        "\n",
        "Because a Markov chain is made from fixed states and fixed probabilities to go from one state to the next. These probabilities can be stored in a matrix called a transition matrix. This very interesting structure will prove a useful analysis tool. Here is an example of a Markov chain with three states and its transition matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_picture(directory + 'img_transition_matrix_schematics.png')"
      ],
      "metadata": {
        "id": "UQVSPg4nGovy"
      },
      "id": "UQVSPg4nGovy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this tutorial, we will first build the transition matrix of our state space. We build this matrix because it contains important information about the dynamics of the system.\n",
        "\n",
        "You might wonder: why make a transition matrix of we already have the behavior space?\n",
        "\n",
        "In reality, there is value in both. They are simply different apporaches.\n",
        "\n",
        "With the state space, we worry about how individual trajectories evolve and study their geometry. When we look at the transition matrix, we look at ensembles of trajectories by looking at transition patterns. One very interesting thing we can (and will) do with the transition matrix is clustering with its eigenvectors. The matrix contains naturally ordered longer-lived dynamics in its eigenvectors, which have a chance of being interpretable.\n",
        "\n",
        "\n",
        "Computationally, the first step is to identify topological states with k-means clustering, like we did in Part 2. We will then choose a transition time for the transition matrix. Finally, we will decompose the matrix into its eigenvectors and try to interpret them relative to our state space.\n",
        "\n",
        "\n",
        " In more formal words, the transition matrix will act as the approximation of the Perron-Froebenius operator that transfer the probaility densities in time and we will apply transfer operators to learn about coarse-grained descriptions. The theoretical basis for this part the the tutorial is explained in [1]."
      ],
      "metadata": {
        "id": "bs39boxPGjIp"
      },
      "id": "bs39boxPGjIp"
    },
    {
      "cell_type": "markdown",
      "id": "859f510a",
      "metadata": {
        "id": "859f510a"
      },
      "source": [
        "## Calculate optimal N"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5851c23a",
      "metadata": {
        "id": "5851c23a"
      },
      "source": [
        "A Markov chain has states and goes from one to the other with probability $P_ij$. The first step is to identify the states with k-means clustering and entropy rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cccc1bbc",
      "metadata": {
        "id": "cccc1bbc"
      },
      "outputs": [],
      "source": [
        "n_seed_range=np.arange(1,1500,100) #Number of partitions to examine\n",
        "n_samples = 3  #Number of random samples to make\n",
        "\n",
        "#Calculate the optimal number of clusters for the embeded space that maximises entropy\n",
        "# with optimal K and M previously established\n",
        "\n",
        "h_seeds=[]\n",
        "\n",
        "for n_seeds in n_seed_range:\n",
        "    h_samples=[]\n",
        "    for idx in range(n_samples):\n",
        "        labels=cl.kmeans_knn_partition(traj_matrix,n_seeds)\n",
        "        h = op_calc.get_entropy(labels)\n",
        "        h_samples.append(h)\n",
        "    h_seeds.append(h_samples)\n",
        "    print('N =',n_seeds,\"Entropy = \",h_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11697563",
      "metadata": {
        "id": "11697563"
      },
      "outputs": [],
      "source": [
        "#Plot the entropy in function of partition number to evaluate the right number of partitions to use in clustering\n",
        "plt.figure(figsize=(10,6))\n",
        "mean = np.mean(h_seeds, axis = 1)\n",
        "std = np.std(h_seeds, axis = 1)\n",
        "plt.errorbar(n_seed_range,mean,yerr = [ std,std ],capsize=4,marker='o',ms=5)\n",
        "plt.xlabel('$N$ (partitions)')\n",
        "plt.ylabel('$h$ (nats/symbol)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c245197c",
      "metadata": {
        "id": "c245197c"
      },
      "outputs": [],
      "source": [
        "N_opt = 250  # Optimal number of partitions, will depend on your own graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84339f42",
      "metadata": {
        "id": "84339f42"
      },
      "source": [
        "## Choose a transition time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0476571",
      "metadata": {
        "id": "d0476571"
      },
      "source": [
        "The probability of going from one state to the next depends on their topology and the time step we look at. We covered the state's shapes in the last section. In this section we find a time step, or transition time $\\tau$, where the system is Markov. A purely Markovian system would be independent of $\\tau$. Unfortunately, in real life, when we work with incomplete information, we need to choose it wisely. To do so, we will look at how two metrics evolve with $\\tau$: the eigenvalues of the transition matrix and the implied time scale. The implied time scale is the implied relaxation time associated with each eigenvalue, following this equation:\n",
        "$$\n",
        "t^{imp}_i (\\tau) = \\frac{-\\tau}{\\log\\lambda_i(\\tau)}\n",
        "$$\n",
        "\n",
        "For small $\\tau$, the system does not have enough time to leave the current partition, and the eigenvalues will be close to unity. As $\\tau$ increases, we leave this transient state. Eventually, for very large $\\tau$, the system will reach its mixing state, the eigenvalues will collapse, and the implied time scale will increase linearly. We aim to choose $\\tau$ in the intermediate state, after the initial fast dynamics, and the mixed state.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35454b13",
      "metadata": {
        "id": "35454b13"
      },
      "outputs": [],
      "source": [
        "range_tau = np.arange(1,100)  #Range of transition times to test\n",
        "nmodes = 3  #Number of eigenmodes to keep\n",
        "n_samples = 3  #Number of random samples to make for averaging\n",
        "dt = 5  #Sampling rate, in frames/second\n",
        "\n",
        "\n",
        "\n",
        "#Arrays to store all relevant quantities for plotting later\n",
        "eigvals_mean_arr = np.zeros((n_samples, range_tau.shape[0], nmodes))\n",
        "eigvals_array = np.zeros((range_tau.shape[0], nmodes))\n",
        "\n",
        "t_imp_mean_arr = np.zeros((n_samples, range_tau.shape[0], nmodes))\n",
        "t_imp_array = np.zeros((range_tau.shape[0], nmodes))\n",
        "\n",
        "for i in range(n_samples):\n",
        "    print(\"Bootstrap sample #\", i)\n",
        "    # Make a different version of labels for each bootstrapped sample\n",
        "    labels_original = ma.array(cl.kmeans_knn_partition(traj_matrix,N_opt),dtype=int)\n",
        "\n",
        "\n",
        "    for tau in range(0, range_tau.shape[0]):\n",
        "        print(\"Transition time: \", tau)\n",
        "        P = op_calc.transition_matrix(labels_original,tau + 1)  #Make the transition matrix\n",
        "        R = op_calc.get_reversible_transition_matrix(P)  #Reversibilize the transision matrix\n",
        "        new_matrix = R.toarray()  #Make the TM into an array\n",
        "        eigvals, eigvecs = op_calc.sorted_spectrum(new_matrix,k=nmodes)  #Calculate its eigenvalies\n",
        "        eigvals_array[tau, :] = eigvals.real  #Keep only the real part\n",
        "        t_imp_array[tau, :] = -(range_tau[tau])/np.log(eigvals.real)  #Calculate t_implied\n",
        "        t_imp_array[tau, :] = t_imp_array[tau, :]/dt  #Divide it by the sampling rate\n",
        "\n",
        "\n",
        "    #Store for averaging\n",
        "    eigvals_mean_arr[i, :, :] = eigvals_array\n",
        "    t_imp_mean_arr[i, :, :] = t_imp_array\n",
        "\n",
        "#Calculate means and stp for each value\n",
        "eigvals_mean = np.mean(eigvals_mean_arr, axis = 0)\n",
        "eigvals_std = np.std(eigvals_mean_arr, axis = 0)\n",
        "\n",
        "t_imp_mean = np.mean(t_imp_mean_arr, axis = 0)\n",
        "t_imp_std = np.std(t_imp_mean_arr, axis = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f726362e",
      "metadata": {
        "id": "f726362e"
      },
      "outputs": [],
      "source": [
        "#Impose colors of your choice for each mode you want to keep\n",
        "colors = [\"k\", \"g\", \"y\", \"b\", \"r\", \"pink\"]\n",
        "\n",
        "\n",
        "for mode in range(1, nmodes):\n",
        "    plt.semilogx(range_tau,eigvals_mean[:,mode], c = colors[mode], label = '$\\lambda$' + str(mode))\n",
        "    plt.fill_between(range_tau,eigvals_mean[:,mode] - eigvals_std[:,mode],eigvals_mean[:,mode] + eigvals_std[:,mode],alpha=.2, color = colors[mode])\n",
        "\n",
        "plt.xlabel(r'$\\tau (frames)$',fontsize=15)\n",
        "plt.ylabel('$\\lambda$',fontsize=15)\n",
        "plt.legend()\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for mode in range(1, nmodes):\n",
        "    plt.plot(range_tau,t_imp_mean[:,mode], c = colors[mode], label = '$\\lambda$' + str(mode))\n",
        "    plt.fill_between(range_tau,t_imp_mean[:,mode] - t_imp_std[:,mode],t_imp_mean[:,mode] + t_imp_std[:,mode],alpha=.2, color = colors[mode])\n",
        "\n",
        "plt.xlabel(r'$\\tau (frames)$',fontsize=15)\n",
        "plt.ylabel('$t_{imp}$ (s)',fontsize=15)\n",
        "plt.legend()\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b8eb73",
      "metadata": {
        "id": "c2b8eb73"
      },
      "source": [
        "From these graphs, we choose an $\\tau$ after the initial transient, which occurs between 0 and 20 frames, and the mixing state that seem to start around 60 frames. We will choose $\\tau = 25$ frames (5 seconds).\n",
        "\n",
        "In a true Markov system, the transition matrix at time $\\tau$ is equal to the initial transition matrix to the $\\tau$ power. This is a version of the Kolmogorov-Chapman identity.\n",
        "\n",
        "$$ T(\\tau) = T_0^\\tau $$\n",
        "\n",
        "We can compare the current eigenvalues with the ones we would obtain with a purely Markov system to give us intuition about how Markov our system is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "226507a5",
      "metadata": {
        "id": "226507a5"
      },
      "outputs": [],
      "source": [
        "range_tau = np.arange(1,100)  #Range of transition times to test\n",
        "nmodes = 3  #Number of eigenmodes to keep\n",
        "n_samples = 3  #Number of random samples to make for averaging\n",
        "dt = 5  #Sampling rate, in frames/second\n",
        "\n",
        "\n",
        "\n",
        "#Arrays to store all relevant quantities for plotting later\n",
        "\n",
        "eigvals_mean_arr_markov = np.zeros((n_samples, range_tau.shape[0], nmodes))\n",
        "eigvals_array_markov = np.zeros((range_tau.shape[0], nmodes))\n",
        "\n",
        "for i in range(n_samples):\n",
        "    print(\"Bootstrap sample #\", i)\n",
        "    # Make a different version of labels for each bootstrapped sample\n",
        "    labels_original_markov = ma.array(cl.kmeans_knn_partition(traj_matrix,N_opt),dtype=int)\n",
        "    P = op_calc.transition_matrix(labels_original_markov, 1)  #Make the transition matrix with tau = 1\n",
        "    R = op_calc.get_reversible_transition_matrix(P)  #Reversibilize the transision matrix\n",
        "    initial_matrix_markov = R.toarray()  #Make the TM into an array\n",
        "    new_matrix_markov = initial_matrix_markov\n",
        "    eigvals, eigvecs = op_calc.sorted_spectrum(initial_matrix_markov, k=nmodes)\n",
        "    eigvals_array_markov[0, :] = eigvals.real\n",
        "\n",
        "    for tau in range(0, range_tau.shape[0]):\n",
        "        print(\"Transition time: \", tau)\n",
        "        new_matrix_markov = np.matmul(new_matrix_markov, initial_matrix_markov)\n",
        "        eigvals, eigvecs = op_calc.sorted_spectrum(new_matrix_markov,k=nmodes)\n",
        "        eigvals_array_markov[tau, :] = eigvals.real\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Store for averaging\n",
        "    eigvals_mean_arr_markov[i, :, :] = eigvals_array_markov\n",
        "\n",
        "\n",
        "#Calculate means and stp for each value\n",
        "eigvals_mean_markov = np.mean(eigvals_mean_arr_markov, axis = 0)\n",
        "eigvals_std_markov = np.std(eigvals_mean_arr_markov, axis = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a29ef9b",
      "metadata": {
        "id": "8a29ef9b"
      },
      "outputs": [],
      "source": [
        "for mode in range(1, nmodes):\n",
        "    plt.semilogx(range_tau,eigvals_mean[:,mode], c = colors[mode], label = '$\\lambda$' + str(mode))\n",
        "    plt.fill_between(range_tau,eigvals_mean[:,mode] - eigvals_std[:,mode],eigvals_mean[:,mode] + eigvals_std[:,mode],alpha=.2, color = colors[mode])\n",
        "\n",
        "    plt.semilogx(range_tau,eigvals_mean_markov[:,mode], \"--\", c = colors[mode], label = ' Markov $ \\lambda$' + str(mode))\n",
        "    plt.fill_between(range_tau,eigvals_mean_markov[:,mode] - eigvals_std_markov[:,mode],eigvals_mean[:,mode] + eigvals_std_markov[:,mode],alpha=.2, color = colors[mode])\n",
        "\n",
        "plt.xlabel(r'$\\tau (frames)$',fontsize=15)\n",
        "plt.ylabel('$\\lambda$',fontsize=15)\n",
        "plt.legend()\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e5a920",
      "metadata": {
        "id": "20e5a920"
      },
      "source": [
        "The Markov model (dotted line) is very close to the experimental data, which confirms that our assumption is reasonable. We can now make the final transition matrix we will work with for the rest of the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make the transition matrix\n",
        "\n",
        "We now have our states ($N$ states) and our transition time $\\tau$. We are ready to build the transition matrix that describes how the bending of the larva evolves in time."
      ],
      "metadata": {
        "id": "5rqzBrK3zr_w"
      },
      "id": "5rqzBrK3zr_w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799fcd07",
      "metadata": {
        "id": "799fcd07"
      },
      "outputs": [],
      "source": [
        "# Final transition matrix with the chosen parameters\n",
        "labels = ma.array(cl.kmeans_knn_partition(traj_matrix,N_opt),dtype=int)\n",
        "tau = 25\n",
        "\n",
        "#Correction of labels excluding states that have not been included in the TM\n",
        "lcs, P= op_calc.transition_matrix(labels,tau, return_connected = True)\n",
        "R = op_calc.get_reversible_transition_matrix(P)\n",
        "transition_matrix_ = R.toarray()\n",
        "final_labels = op_calc.get_connected_labels(labels,lcs)  #Makes sure only the labels visited in the TM are included\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyse the matrix to get longer-lived dynamics"
      ],
      "metadata": {
        "id": "WyuDPVrdz9ry"
      },
      "id": "WyuDPVrdz9ry"
    },
    {
      "cell_type": "markdown",
      "id": "6d4ae450",
      "metadata": {
        "id": "6d4ae450"
      },
      "source": [
        "There is something very convenient about the transition matrix: the first eigenvectors describe the longer-lived, or slowest dynamics. We can call these metastable states, which are regions that the system visits often. We can use these eigenvectors to cluster the state space and learn something about it. There is substantial theory beyond the scope of this tutorial behind this statement. If you are interested to understand the underlying assumptions made to do this, here are some useful references [1], [2], [3].\n",
        "\n",
        " In this last section, we will analyze this transition matrix by looking at its first eigenmode. First, we plot how the eigenvalues are distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079c113b",
      "metadata": {
        "id": "079c113b"
      },
      "outputs": [],
      "source": [
        "#Extract and plot the eigenmodes\n",
        "eigvals,eigvecs = op_calc.sorted_spectrum(transition_matrix_,k = 20)\n",
        "\n",
        "plt.plot(eigvals.real[1:],\"o\")\n",
        "plt.xlabel(\"Mode\", fontsize = 15)\n",
        "plt.ylabel(\"Eigenvalue\", fontsize = 15)\n",
        "plt.ylabel\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b2d146e",
      "metadata": {
        "id": "3b2d146e"
      },
      "source": [
        "We could analyze each mode individually. Here, we will only look at the first one as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ca5996",
      "metadata": {
        "id": "42ca5996"
      },
      "outputs": [],
      "source": [
        "#Choose which eigenvector you want to look at\n",
        "mode = 0   #Mode 0 will lead to the first eigenvector\n",
        "current_eigenvec =eigvecs [final_labels,mode].real  #Look at the current eigenvector with the connected labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91bfc488",
      "metadata": {
        "id": "91bfc488"
      },
      "source": [
        "A good first step is to look at how the eigenvector evolves with time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3eaa71",
      "metadata": {
        "id": "5b3eaa71"
      },
      "outputs": [],
      "source": [
        "#Look at the time series\n",
        "plt.plot(current_eigenvec)\n",
        "plt.xlabel(\"Time (frames)\", fontsize = 15)\n",
        "plt.ylabel(r'$\\phi_{1}$', fontsize = 15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6a6068",
      "metadata": {
        "id": "fa6a6068"
      },
      "source": [
        "We notice that this vector has a higher amplitude during the first 1000 frames, then stabilizes. It seems to partition two sections of the time series. There is then some dynamics that occur only in the first 1000 frames. If we could look at the full video, we would get an intuitive interpretation of what happens. Indeed, in the first 1000 frames, the larva does some type of short scale exploration. It turns very frequently with very small forward crawling bouts in between. Then, it picks a direction, and starts crawling without turning at all for the rest of the video. This is most likely what the transition matrix's first eigenvector is picking up.\n",
        "\n",
        "\n",
        " With a UMAP embedding, we see how the eigenvector partitions the whole space by colouring the time points with the corresponding amplitude of the vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8917aa0",
      "metadata": {
        "id": "e8917aa0"
      },
      "outputs": [],
      "source": [
        "# We normalize the vector\n",
        "color_abs = np.max(np.abs(current_eigenvec))\n",
        "scaler = preprocessing.MinMaxScaler(feature_range=(-color_abs, color_abs))\n",
        "list = current_eigenvec.reshape(-1,1)\n",
        "normalized_eigenvec = scaler.fit_transform(list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a505355",
      "metadata": {
        "id": "9a505355"
      },
      "outputs": [],
      "source": [
        "#Plot UMAP\n",
        "reducer = umap.UMAP(n_neighbors=200,min_dist=0.1)\n",
        "embedding = reducer.fit_transform(u_withVar)\n",
        "plt.scatter(embedding[:,0], embedding[:, 1],c = normalized_eigenvec, cmap = \"coolwarm\", s = 0.8)\n",
        "plt.colorbar()\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803681ff",
      "metadata": {
        "id": "803681ff"
      },
      "source": [
        "\n",
        "This plot gives intuition about the structure of the state space itself. The areas with the highest vector amplitudes are all the points from the beginning of the time series (turning), whereas the rest form a conical shape (forward crawling).\n",
        "\n",
        "To get further intuition about this first eigenvector, we related its amplitude with various parameters, such as the angle of the anterior body of the larva relative displacement, turning speed, etc. We will not give the codes here as they do not contribute to the method, but in the following plot we show first SVD mode against the anterior angle, colored by the amplitude of the first eigenvector."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_picture(directory + \"img_larva_svd0_vs_ant_angle_vs_phi1.png\")"
      ],
      "metadata": {
        "id": "ay9Rfa3B3CdB"
      },
      "id": "ay9Rfa3B3CdB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this plot, we can see that\n",
        "\n",
        " 1- the first SVD mode is correlated to the anterior angle.\n",
        "\n",
        "  2- The eigenvector is low (or slightly positive) when the angle is close to 0 (forward crawling, or forward crawling with slight head bend), whereas it is high whenever the angle is important.\n",
        "  \n",
        "  This confirms our intuition that the first eigenvector partitions the short-scale exploration with a lot of turning from the long-range forward crawling bouts.\n",
        "\n",
        "With similar analyses, we could show that the second eigenvector splits right and left turns. As we move further down the eigenvectors, they will describe faster dynamics.\n",
        "\n",
        "We leave the rest of the analysis to you with the larva data, or your own. We hope this has been interesting at least, maybe useful. Good luck, have fun, and do not hesitate to contact me for questions (see README file)!\n"
      ],
      "metadata": {
        "id": "lKRSBcW-3izj"
      },
      "id": "lKRSBcW-3izj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\textit{Disclaimer}$: In this process, we reversibilize the transition matrix to ensure optimal clustering (see [1,2]). This might lead to issues in highlt cyclical behaviors anf prevent interpretability in the Markov test, and even in the eigenvectors themselves."
      ],
      "metadata": {
        "id": "BleXmmr78380"
      },
      "id": "BleXmmr78380"
    },
    {
      "cell_type": "markdown",
      "id": "9167e649",
      "metadata": {
        "id": "9167e649"
      },
      "source": [
        "References\n",
        "\n",
        "[1] Costa, C. A., et al., \"Maximally predictive states: From partial observations to long timescales\", Chaos, 2023.\n",
        "\n",
        "[2] G. Froyland and M. Dellnitz, “Detecting and locating near-optimal almost-invariant sets and cycles,” SIAM J. Sci. Comput. 2003.\n",
        "\n",
        "[3] G. Froyland, G. A. Gottwald, and A. Hammerlindl, “A computational method to extract macroscopic variables and their dynamics in multiscale systems,” 2014."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}